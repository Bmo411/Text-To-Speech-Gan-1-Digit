# Proyecto: Vocoder GAN para ConversiÃ³n de Espectrogramas a Audio

Este proyecto constituye la segunda etapa de un sistema de texto a voz (TTS), donde se implementa un vocoder personalizado basado en una red Generativa Adversarial (GAN). Su propÃ³sito es convertir espectrogramas mel generados por Tacotron 2 en seÃ±ales de audio naturales.

---

## ğŸ”§ Estructura del Sistema TTS

El sistema se compone de dos etapas:

1. **Tacotron 2 (no incluido en este repositorio)**  
   Convierte texto en espectrogramas mel.

2. **GAN Vocoder (este proyecto)**  
   Transforma los espectrogramas mel en audio crudo.

---

## ğŸ“ Archivos Importantes

- `TestTTS.ipynb`: Notebook principal con todo el flujo de trabajo.
- `README.md`: Este archivo de documentaciÃ³n.
- `requirements.txt`: Lista de dependencias necesarias (opcional, puede ser generado).

---

## ğŸ§ª Dataset Utilizado

**Spoken Digit Dataset (TensorFlow Datasets)**  
- Audio de dÃ­gitos del 0 al 9 hablados por diferentes personas.
- 8 kHz de muestreo.
- Cada muestra de audio se transforma en un espectrograma mel como entrada para la GAN.

---

## ğŸ”„ Flujo de Trabajo

### 1. AdquisiciÃ³n y Preprocesamiento de Datos

- Descarga del dataset desde TensorFlow Datasets.
- CÃ¡lculo de los espectrogramas mel usando `librosa`.
- Emparejamiento (mel, audio) para entrenamiento.
- NormalizaciÃ³n de datos para estabilidad en el entrenamiento.

### 2. DiseÃ±o del Modelo GAN

#### Generador
- Arquitectura basada en LSTM.
- Entrada: secuencia de espectrogramas mel.
- Salida: seÃ±al de audio en el dominio temporal.

#### Discriminador
- LSTM bidireccional.
- Entrada: seÃ±al real o generada.
- Salida: probabilidad de autenticidad.

### 3. Funciones de PÃ©rdida

- **PÃ©rdida Adversarial (Binary Crossentropy)**
- **PÃ©rdida de ReconstrucciÃ³n (MSE o L1 loss)**

### 4. Entrenamiento

- Entrenamiento alternado de generador y discriminador.
- OptimizaciÃ³n con Adam.
- VisualizaciÃ³n periÃ³dica de seÃ±ales generadas.
- Almacenamiento de mÃ©tricas.

### 5. EvaluaciÃ³n

- ComparaciÃ³n de audio real vs. generado.
- MÃ©tricas implementadas:
  - MSE (Error CuadrÃ¡tico Medio)
  - PSNR (RelaciÃ³n SeÃ±al a Ruido de Pico)
  - SNR (RelaciÃ³n SeÃ±al a Ruido)
- VisualizaciÃ³n de grÃ¡ficas de forma de onda y espectrogramas.

---

## â–¶ï¸ Instrucciones de Uso

### 1. Clona el repositorio

```bash
git clone https://github.com/tu_usuario/gan-vocoder-tts.git
cd gan-vocoder-tts
```

### 2. Instala las dependencias

```bash
pip install -r requirements.txt
```

### 3. Ejecuta el notebook

```bash
jupyter notebook TestTTS.ipynb
```

---

## ğŸ“Š Resultados y VisualizaciÃ³n

- Se presentan comparativas entre seÃ±al generada y real.
- GrÃ¡ficos de error y evoluciÃ³n del entrenamiento.
- Audio de salida que puede ser reproducido desde el notebook.

---

## ğŸ“š TecnologÃ­as Usadas

- Python 3.8+
- TensorFlow 2.x
- NumPy, librosa, matplotlib
- Jupyter Notebook

---

## ğŸ‘¨â€ğŸ’» Autor

**@homero-sepulveda**  
Ingeniero mecatrÃ³nico | Especializado en IA, sistemas embebidos y robÃ³tica.

---

## ğŸ“„ Licencia

Este proyecto es de uso acadÃ©mico y experimental.

---

## ğŸ“ Notas Adicionales

- El proyecto se puede escalar para otros datasets de mayor calidad.
- Para una voz completa, debe integrarse con Tacotron 2 o un sistema similar de texto a espectrograma.
- Puede extenderse a vocoders mÃ¡s complejos como HiFi-GAN o WaveGAN.

